%YAML:1.0

# camera calibration 
model_type: PINHOLE
camera_name: camera
# Image Downsample need
down_sample: 1
# The size of the image after scaling, the current scaling ratio is 0.3
image_width: 480 # origin: 1600
image_height: 330 # origin: 1100
focal_length: 460 #920

distortion_parameters:
   k1: -0.1008504099655989
   k2: 0.08905706623788286
   p1: 0.0007516966627205781
   p2: -0.0011958374307601393
projection_parameters:
   fx: 282.25884768 # 940.862825677534 * 480 / 1600
   fy: 281.56647705 # 938.554923506332 * 330 / 1100
   cx: 239.74880925 # 799.162697523358 * 480 / 1600
   cy: 167.78862207 # 559.295406893583 * 330 / 1100

# Rotation from lidar frame to camera center, cam^R_LiDAR (aka R_CL)
extrinsicRotation: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0.99976153,  0.02147506,  0.00396403,
           0.00401332, -0.00225255, -0.99998941,
          -0.0214659 ,  0.99976685, -0.0023382 ]
# Translation from lidar frame to camera center, cam^T_LiDAR
extrinsicTranslation: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [ 0.11023908, -0.05627601, -0.04082231] #-0.086246, 0.015, 0.018 

#feature traker parameters
# no use
max_keyline_count: 120 # 80
keyline_detector_octaves: 1
keyline_detector_scale: 1.2

lbd_descriptor_width_of_band: 7

max_keypoint_count: 100 # 50
min_keypoint_dist: 40
F_threshold: 1.0
sliding_window_size: 5

#laser registrator parameters
laser_scan_number: 16
horizon_scans: 1800  # 1875
minimum_range: 0.3
angle_res_x: 0.2   # 0.192
angle_res_y: 2.0
angle_bottom: 15.0
crop_near: 1.0
crop_far: 80

edge_threshold: 2
surf_threshold: 0.2  # for ugv, if you want to get more accurate poses, this could set smaller (0.2 is perfect)
nearest_feature_search_dist: 25
occlude_threshold: 0.3
range_diff_threshold: 0.02

# point cloud removes distortion
distortion: 0        # There are some problems in the implementation of the algorithm, it is best set 0
scan_period: 0.1     # The time of one lidar scan, unit is second
distance_sq_threshold: 25
nearby_scan: 2.5
visual_weight_max: 0.5 # [0,1]   # The maximum weight coefficient of the visual part residual item in the front-end odometry part

# submap para
submap_length: 45    # The number of lidar frames contained in the sub-picture affects the number of sub-pictures (the sub-pictures are at least 5m apart before preparing to generate one)
keep_squre_distance: 3600 # 3600 means 60 meters
# thumbnail para
ndt_resolution_thumbnail: 2.0
ndt_resolution_match: 3.0  # WARNING!!! If the program fails with a segmentation fault, you can set a larger value to avoid it.
need_check_direction: 0 # On a drone, if your equipment (default is camera) Z axis is facing down, such as the installation 
                        # method in GrAco dataset(45 degree face down), set 1, otherwise set 0

# output odom para, tum format
need_pub_odom: 1
out_odom_path: /home/sysu-rapid/gacm_output/data/testSavemap/   # must end with "/"

# for memory save
cache_path: /home/sysu-rapid/gacm_output/cache/     # must end with "/"

# no use / deprecate
gt_path: deprecate
gt_start_time: 0
out_gt_path: deprecate
air_gps: 0



